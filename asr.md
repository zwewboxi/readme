
##  **ASR 模型参数规模汇总**

| 模型名称 | 参数量（约） | 发布 | 开源 | license | 实时转录 | 语言 | 声纹识别 |自动切分时间戳 |备注与架构说明 |
| :---- | :----- | :---- | :---- | :------ |:--------- |:---- |:---- |:------- |:------- |
| **Fun-ASR** | **7.7B** | 阿里 | √ | MIT License | √ |支持多达31种语言自由混说。具体支持中文（普通话、粤语、吴语等）、英语、日语及多种汉语方言口音 | √ | √ |音频编码器0.7B + LLM解码器7B；采用Conformer+Transformer混合架构，兼顾局部与全局特征。 |
| **Fun-ASR-nano** | **0.8B** | 阿里 | √ | Apache License 2.0 | √ | 覆盖31种语言 | ✕ | ✕ | 轻量版，音频编码器0.2B + LLM解码器0.6B；设计目标为高性能、低延迟。 |
| **GLM-ASR-2512** | **未公开 (云端)** | 智谱 | ✕ |   |   |   |   |   | 云端模型，官方文档未公开参数量；在复杂场景测试中字符错误率(CER)为0.0717%。 |
| **GLM-ASR-Nano-2512** | **1.5B** | 智谱 | √ | Apache License 2.0 |     |除标准普通话和英语外，模型针对粤语及其他方言进行了深度优化 |      |      |开源端侧模型，在多项基准测试中超越Whisper v3，专门优化了低音量语音和方言识别。 |
| **Whisper-large-v3** | **1.5B** | OpenAI | √ | MIT License | ✕ |99种语言 | √ | √ |多语言通用模型，基于编码器-解码器的Transformer架构，使用68万小时弱监督数据训练。 |
| **Seed-ASR** | **~12B** | 字节 | ✕ |     |     |     |     |     | 基于LLM的长上下文ASR，采用混合专家大语言模型架构。 |
| **FireRed-ASR-LLM** | **8.3B** | 小红书 | √ | Apache License 2.0 |     | 支持普通话、中国方言和英语 |     |     | Encoder-Adapter-LLM架构，集成LLM能力以追求SOTA精度。 |
| **FireRed-ASR-AED** | **1.1B** | 小红书 | √ | Apache License 2.0 |     | 支持普通话、中国方言和英语 |     |     | Conformer编码器+Transformer解码器 (AED)架构，在效率与精度间平衡。 |
| **Paraformer** |      | 阿里 | √ |   | √ | 支持多语种，涵盖英语、法语、德语、西班牙语等 | ✕ | √ | 非自回归模型，注重大规模工业级语料上的噪声鲁棒性，追求高推理速度。 |
| **seamless-m4t-large-v2** | **2.3B** | Meta | √ | cc-by-nc-4.0 | ✕ | 支持近100种语言的语音和文本互译 |     |     | 多任务统一模型，专注于多语言语音翻译与识别。 |

---

##  **各模型在开源数据集上的 WER%**

| 测试集 | Fun-ASR | Fun-ASR-nano | Whisper-large-v3 | Seed-ASR* | FireRed-ASR | Kimi-Audio | Step-Audio2 |
|--------|----------|---------------|------------------|-----------|-------------|------------|-------------|
| AIShell1 | 1.22 | 1.76 | 4.72 | 1.63 | 0.54 | 0.71 | 0.63 |
| AIShell2 | 2.30 | 2.80 | 4.68 | 2.76 | 2.58 | 2.86 | 2.10 |
| Fleurs-zh | 2.64 | 3.47 | 5.18 | 3.23 | 4.81 | 3.11 | 2.68 |
| Fleurs-en | 5.84 | 7.95 | 6.23 | 9.39 | 10.79 | 6.99 | 3.03 |
| Librispeech-clean | 1.57 | 1.75 | 1.86 | 2.80 | 1.84 | 1.32 | 1.17 |
| Librispeech-other | 3.24 | 4.37 | 3.43 | 5.69 | 4.52 | 2.63 | 2.42 |
| WenetSpeech Meeting | 6.49 | 8.78 | 18.39 | 7.07 | 4.95 | 6.24 | 4.75 |
| WenetSpeech Net | 5.46 | 6.28 | 11.89 | 4.84 | 4.94 | 6.45 | 4.67 |

> **注：** Seed-ASR* 是通过其官方API评估的结果。

---

##  **各模型在工业数据集上的 WER%（表2数据）**

| 测试集 | Fun-ASR | Fun-ASR-nano | Seed-ASR | Whisper-large-v3 | FireRed-ASR | Kimi-Audio | Paraformer v2 |
|--------|----------|---------------|-----------|------------------|-------------|------------|---------------|
| In-house | 6.66 | 7.26 | 7.20 | 16.58 | 10.10 | 9.02 | 8.11 |
| Fairfield | 4.66 | 5.43 | 4.59 | 22.21 | 7.49 | 10.95 | 9.55 |
| Home Scenario | 5.17 | 6.02 | 8.08 | 18.17 | 9.67 | 23.79 | 6.87 |
| Complex Background | 11.29 | 17.07 | 12.90 | 32.57 | 15.56 | 15.56 | 15.19 |
| English General | 14.22 | 15.87 | 15.65 | 18.56 | 21.62 | 18.12 | 19.48 |
| Opensource | 3.60 | 4.65 | 3.83 | 7.05 | 5.31 | 3.20 | 6.23 |
| **Average** | **7.60** | **9.38** | **8.71** | **19.19** | **11.63** | **13.54** | **10.91** |

---

##  **多语言 ASR 模型对比（WER%）**

| 语言 | 测试集 | Fun-ASR-ML | Kimi-Audio | Whisper-large-v3 | dolphin-small | seamless-m4t-large-v2 |
|------|--------|-------------|------------|------------------|---------------|-----------------------|
| 中文 | fleurs | 3.00 | 2.69 | 4.71 | 5.46 | 5.15 |
| 中文 | commonvoice | 5.76 | 7.21 | 12.61 | 9.94 | 10.76 |
| 英文 | fleurs | 3.18 | 4.40 | 4.11 | N.A. | 6.59 |
| 英文 | commonvoice | 1.67 | 10.31 | 9.66 | N.A. | 7.62 |
| 印尼语 | fleurs | 8.10 | N.A. | 6.07 | 15.86 | 9.36 |
| 泰语 | fleurs | 6.00 | N.A. | 8.48 | 9.66 | 9.25 |
| 越南语 | fleurs | 5.50 | N.A. | 6.51 | 15.62 | 8.07 |

---

##  **专项能力对比**

### **1. 流式 ASR**
| 测试集 | Fun-ASR（流式） | Fun-ASR-nano（流式） | Seed-ASR（流式） |
|--------|-----------------|---------------------|-----------------|
| In-house | 7.00 | 7.97 | 8.64 |
| Fairfield | 5.33 | 6.92 | 5.51 |
| Home Scenario | 5.33 | 6.51 | 9.70 |
| Complex Background | 12.50 | 14.83 | 15.48 |

### **2. 噪声鲁棒性（Fun-ASR 自身对比）**
| 环境 | 无噪声训练 | 有噪声训练 | 噪声训练+RL |
|------|------------|------------|-------------|
| dinner | 14.02 | 9.88 | 9.55 |
| supermarket | 14.27 | 8.81 | 8.75 |
| 平均 | 13.32 | 11.58 | 11.45 |

### **3. 中英混说**
| 测试集 | 无混说训练 | 有混说训练（无RL） | 有混说训练（有RL） |
|--------|------------|-------------------|-------------------|
| A | 4.53 | 1.70 | 1.59 |
| B | 4.76 | 4.56 | 4.50 |

### **4. 热词定制效果（部分示例）**
| 主题 | 无RL的准确率/召回率 | 有RL的准确率/召回率 |
|------|-------------------|-------------------|
| 人名 | 1.00 / 0.95 | 1.00 / 1.00 |
| 生物 | 0.98 / 0.99 | 0.97 / 1.00 |
| 哲学 | 0.99 / 0.96 | 0.99 / 0.97 |

---

##  **总结对比**

- **参数规模**：Seed-ASR 最大（~12B），Fun-ASR 居中（7.7B），FireRed-ASR 和 Whisper 较小（1.1B–1.5B）。
- **精度表现**：
  - 开源数据集上，FireRed-ASR 和 Kimi-Audio 在某些中文任务上略优。
  - 工业数据集上，Fun-ASR 在多数场景下表现最佳，尤其在噪声、复杂背景下。
- **多语言**：Fun-ASR-ML 在东南亚语言上表现优于其他多语言模型。
- **实用能力**：Fun-ASR 在流式、噪声鲁棒、混说、热词定制等方面均有专门优化，适合工业部署。

---
