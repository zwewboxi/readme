# 26.1月汇报 Qwen3-VL

## **一. 模型架构**
<img src="images/qwen3vl_arc.jpg" width="90%">

## **二. 2D-RoPE计算详解**

### 1、参数设定
- **嵌入维度**：`$d_model$ = 8`（实际常用768、1024等）
- **频率基数**：`base = 10000`（行和列通常使用相同基数，也可不同）
- **测试位置**：
  - 位置0：`(row=1, col=2)`
  - 位置1：`(row=3, col=4)`

### 2、频率向量计算

对于维度 i（0 ≤ i < $$\frac{d_{model}}{2}$$），频率计算公式为：  
$$\theta_{i}=base^{-\frac{2i}{d_{model}}}$$

当 d_model=8 时，共有4个频率（对应4组复数对）：

| i | 计算公式 | 近似值 |
|---|---------|-------|
| 0 | $1000^{-\frac{0}{8}}$ | 1.0 |
| 1 | $1000^{-\frac{2}{8}}$ | 0.1 |
| 2 | $1000^{-\frac{4}{8}}$ | 0.01 |
| 3 | $1000^{-\frac{6}{8}}$ | 0.001 |

### 3、旋转角度计算

对于位置 (row, col)，每个维度的旋转角度为：   
$$φ_{i}=row\times\theta_{i}+col\times\theta_{i}$$

**位置0 (1,2)：**
- φ₀ = 1×1 + 2×1 = 3
- φ₁ = 1×0.1 + 2×0.1 = 0.3
- φ₂ = 1×0.01 + 2×0.01 = 0.03
- φ₃ = 1×0.001 + 2×0.001 = 0.003

**位置1 (3,4)：**
- φ₀ = 3×1 + 4×1 = 7
- φ₁ = 3×0.1 + 4×0.1 = 0.7
- φ₂ = 3×0.01 + 4×0.01 = 0.07
- φ₃ = 3×0.001 + 4×0.001 = 0.007

### 4、旋转矩阵应用

将8维嵌入向量视为4个复数对：  
[($q_{0}$, $q_{1}$), ($q_{2}$, $q_{3}$), ($q_{4}$, $q_{5}$), ($q_{6}$, $q_{7}$)]

对每个复数对应用旋转矩阵：

$$q_{2i}^{\prime}=q_{2i}\cos\varphi_{i}-q_{2i+1}\sin\varphi_{i}$$
$$q_{2i+1}^{\prime}=q_{2i}\sin\varphi_{i}+q_{2i+1}\cos\varphi_{i}$$

<img src="images/RoPE.png" width="90%">

### 5、实例计算（位置0）

**原始向量：**  
q = [1, 0, 0, 1, 0.5, 0.5, 1, 1]

**第一组 (i=0, φ=3)：**
- cos(3) ≈ -0.9899925, sin(3) ≈ 0.1411200
- $q_{0}^{\prime}$ = 1 × (-0.9899925) - 0 × 0.1411200 = -0.9899925
- $q_{1}^{\prime}$ = 1 × 0.1411200 + 0 × (-0.9899925) = 0.1411200

**第二组 (i=1, φ=0.3)：**
- cos(0.3) ≈ 0.9553365, sin(0.3) ≈ 0.2955202
- $q_{2}^{\prime}$ = 0 × 0.9553365 - 1 × 0.2955202 = -0.2955202
- $q_{3}^{\prime}$ = 0 × 0.2955202 + 1 × 0.9553365 = 0.9553365

**第三组 (i=2, φ=0.03)：**
- cos(0.03) ≈ 0.9995500, sin(0.03) ≈ 0.0299955
- $q_{4}^{\prime}$ = 0.5 × 0.9995500 - 0.5 × 0.0299955 = 0.48477725
- $q_{5}^{\prime}$ = 0.5 × 0.0299955 + 0.5 × 0.9995500 = 0.51477275

**第四组 (i=3, φ=0.003)：**
- cos(0.003) ≈ 0.9999955, sin(0.003) ≈ 0.00299999
- $q_{6}^{\prime}$ = 1 × 0.9999955 - 1 × 0.00299999 = 0.99699551
- $q_{7}^{\prime}$ = 1 × 0.00299999 + 1 × 0.9999955 = 1.00299549

**旋转后向量：**  
$q^{\prime}$ = [
  -0.9899925, 0.1411200,
  -0.2955202, 0.9553365,
  0.48477725, 0.51477275,
  0.99699551, 1.00299549
]

### 6、注意力分数计算
$$score=q^{\prime}\cdot k^{\prime}=\sum q^_{i}{\prime}\times k_{i}^{\prime}$$

#### a. 计算位置1的键向量旋转

**原始键向量：**  
k = [0, 1, 1, 0, 0.5, 0.5, 1, 1]

**旋转角度：** φ₀=7, φ₁=0.7, φ₂=0.07, φ₃=0.007

**旋转后键向量：**  
$k^{\prime}$ = [
  -0.6569866, 0.7539023,      # i=0, φ=7  
  0.7648422, 0.6442177,       # i=1, φ=0.7  
  0.4637923, 0.5337351,       # i=2, φ=0.07  
  0.99297554, 1.00697546      # i=3, φ=0.007 
]

#### b. 点积计算

各项乘积：
- (-0.9899925)×(-0.6569866) ≈ 0.650
- 0.1411200×0.7539023 ≈ 0.106
- (-0.2955202)×0.7648422 ≈ -0.226
- 0.9553365×0.6442177 ≈ 0.615
- 0.48477725×0.4637923 ≈ 0.225
- 0.51477275×0.5337351 ≈ 0.275
- 0.99699551×0.99297554 ≈ 0.990
- 1.00299549×1.00697546 ≈ 1.010

**总分：** 0.650+0.106-0.226+0.615+0.225+0.275+0.990+1.010 = 3.645

此分数已编码了两个位置的相对位置信息。

---


## **三. 频率基插值**

### 3.1 频率基数学定义
频率基：
$$\theta_{i}=10000^{-\frac{2i}{D}},i=0,1\ldots,\frac{D}{2}$$

其中D是维度，i是维度索引。

### 3.2 插值的核心思想
Qwen3-VL使用**频率基缩放**来适应新的网格尺寸。具体过程：

设预训练时：
垂直方向最大位置索引：$M_{pretrain}$ = 23 (24个patch，索引0-23)
水平方向最大位置索引：$N_{pretrain}$ = 23

新图像(9376×1248)：
垂直方向最大位置索引：$M_{new}$ = 88 (89个patch，索引0-88)
水平方向最大位置索引：$N_{new}$ = 669 (670个patch，索引0-669)

### 3.3 计算缩放因子
$s_{h}$ = ($M_{pretrain}$ + 1) / ($M_{new}$ + 1) = 24/89 ≈ 0.2697
$s_{w}$ = ($N_{pretrain}$ + 1) / ($N_{new}$ + 1) = 24/670 ≈ 0.03582


### 3.4 调整后的频率基
新的频率基通过原始频率基的幂运算得到：
$$\theta_{h},d^{new}=\theta_{d}^{s_{h}=(10000^{-\frac{2i}{D}})^{s_{h}}=10000^{-\frac{2i\cdot s_{h}}{D}}$$     
$$\theta_{w},d^{new}=\theta_{d}^{s_{w}=(10000^{-\frac{2i}{D}})^{s_{w}}=10000^{-\frac{2i\cdot s_{w}}{D}}$$

### 3.5 位置编码计算
对于位置(i,j)的patch，其RoPE旋转角度为：

$φ_h(i,d)=i\cdot\theta_h,d^{new}$    
$φ_w(j,d)=j\cdot\theta_w,d^{new}$


### 3.6 MRoPE计算
将视频切分成多个时间帧，对于位置(t,i,j)的patch，其RoPE旋转角度为：

$φ_t(t,d)=t\cdot\theta_t,d^{new}$    
$φ_h(i,d)=i\cdot\theta_h,d^{new}$    
$φ_w(j,d)=j\cdot\theta_w,d^{new}$    


## 四. Vision Encoder内部结构和DeepStack处理

### 4.1 Vision Encoder (SigLIP-2) 结构
SigLIP-2是Vision Transformer (ViT) 架构：
<img src="images/vit.png" width="90%">
1. **Patch嵌入层**：
   输入 $∈ ℝ^(3×H×W)$ → Patch投影 $∈ ℝ^(N×D)$
   其中 $N = (\frac{H}{P}) × (\frac{W}{P})$, P=14, D=768或1024
   

2. **Transformer层** (L层，如19层)：
   每层包含：
   - 层归一化 (LayerNorm)
   - 多头自注意力 (MSA) with 2D-RoPE
   - 前馈网络 (FFN)

   数学上，第l层：
   $z_l^{\prime} = LN(z_{l-1})+ MSA(LN(z_{l-1})$
   $z_l = z_l^{\prime} + FFN(LN(z_l^{\prime}))$
   
   其中MSA应用了2D-RoPE位置编码。

### 3.2 DeepStack特征选择
假设Vision Encoder有19层，DeepStack选择第6, 12, 18层的输出：

设第l层输出为 F_l ∈ ℝ^(N×D_v)，其中 D_v = 768：

- $F_6 ∈ ℝ^(59630×768)$ - 中级特征
- $F_{12} ∈ ℝ^(59630×768)$ - 高级特征  
- $F_{18} ∈ ℝ^(59630×768)$ - 深层语义特征

### 3.3 每个特征的处理流程  
对于每个选中的特征 $F_l$：   

1. **MLP投影**：    
   $F_l^{\prime} = σ(F_l W_1^l + b_1^l) W_2^l + b_2^l$     
   $W_1^l ∈ ℝ^{768×2048}, W_2^l ∈ ℝ^{2048×4096}$     

2. **2×2空间压缩**：    
   将 $F_l^{\prime}$ 重塑为2D网格：    
   $G_l = reshape(F_l^{\prime}, (89, 670, 4096))$     
   
   2×2平均池化：    
   $G_l^{\prime}[i,j,:] = 1/4 ∑_{m=0}^1 ∑_{n=0}^1 G_l[2i+m, 2j+n, :]$     
   输出尺寸：(44, 335, 4096)     

3. **展平**：
   $V_l = flatten(G_l^{\prime}) ∈ ℝ^{14740×4096}$
   

## 4. DeepStack注入LLM

### 4.1 LLM输入序列构造
设文本token序列为 $T ∈ ℝ^({L_t×4096}$，其中 $L_t$ 是文本长度。

视觉token初始化为0：
$V_init = 0 ∈ ℝ^{14740×4096}$

初始LLM输入：
$H_0 = [T; V_init] ∈ ℝ^{(L_t+14740)×4096}$

### 4.2 注入时间和方式
DeepStack在LLM的**前3层**注入视觉特征：

**第1层注入**：
1. LLM第1层处理：
   $H_1^{\prime} = LLM-Layer_1(H_0)$
 
2. 注入 V_6（来自Vision Encoder第6层）：
   $H_1[视觉位置, :] = H_1'[视觉位置, :] + V_6$
   
   其中视觉位置 = 索引 $L_t$ 到 $L_t+14740-1$

**第2层注入**：
$H_2^{\prime} = LLM-Layer_2(H_1)$
$H_2[视觉位置, :] = H_2'[视觉位置, :] + V_12$


**第3层注入**：
$H_3^{\prime} = LLM-Layer_3(H_2)$
$H_3[视觉位置, :] = H_3'[视觉位置, :] + V_18$


### 4.3 后续层处理
第4层及以后，不再注入新的视觉特征：
$H_l = LLM-Layer_l(H_{l-1}), l ≥ 4$

## 三、图像处理流程（以9376×1248为例）

### 1. 视觉编码器（Vision Encoder）
Qwen3-VL使用**SigLIP-2**作为视觉编码器，支持动态分辨率输入。

#### a) Patch分割与线性投影
- **输入图像尺寸**：H = 1248, W = 9376，RGB三通道 ⇒ 张量形状为 `(3, 1248, 9376)`
- **Patch大小**：假设使用14×14（SigLIP常见配置）
  - 垂直Patch数：Nh = H/14 = 1248/14 ≈ 89
  - 水平Patch数：Nw = W/14 = 9376/14 ≈ 670
  - 总Patch数：N = Nh × Nw ≈ 89 × 670 ≈ 59,630

- **线性投影**：
  - 每个14×14×3的Patch通过可学习投影矩阵 $W_p ∈ ℝ^{14×14×3}×D$ 映射为D维向量
  - 输入Patch张量形状：`(89, 670, 14, 14, 3)` 展开为 `(89, 670, 588)`
  - 投影计算：$Z_o = Flatten(Patches) · W_p $⇒ 输出形状 `(89, 670, D)`

#### b) 位置编码：2D-RoPE + 插值
采用**2D-RoPE**（Rotary Position Embedding）为每个Patch注入位置信息：
- 对于位置(i,j)的Patch，其对应的RoPE旋转角度为：
  $$\theta_{i}=i ·base^{-\frac{2d}{D}}$$
  $$\theta_{j}=j ·base^{-\frac{2d}{D}}$$
  
  其中d为维度索引，`base`为旋转基数（如10,000）
- 对于9376×1248的高分辨率，需对绝对位置嵌入进行**双线性插值**

#### c) 视觉编码器前向传播
SigLIP-2由多层Transformer块组成，每层包括：
- 多头自注意力（MSA）+ RoPE位置编码
- 前馈网络（FFN）
- 残差连接与LayerNorm

**维度变化**：输入`(89,670, D)` → 输出`(89,670, D)`

#### d) 多层特征抽取（DeepStack）
从不同层抽取视觉特征以增强细粒度感知：
- 假设从第l₁, l₂, l₃层抽取特征F₁₁, F₁₂, F₁₃，形状均为`(89,670, D)`
- 每个特征经过独立的**MLP merger**进行降维与对齐：     
  Merger(F₁) = σ(F₁W₁ + b₁)W₂ + b₂     
  输出形状变为`(89,670, D')`     

#### e) 2×2特征压缩
为减少视觉token数量，将相邻的2×2个Patch的特征合并为1个视觉token：
- 输入特征图尺寸：89 × 670
- 2×2池化后尺寸：44 × 335 ⇒ 总视觉token数$N_visual$ = 44 × 335 ≈ 14,740
- 输出视觉token张量形状：`(14,740, D')`

#### f) 输入LLM
视觉token与文本token拼接后输入Qwen3 LLM：
- 最终输入序列长度 = 文本token数 + 14,740
- 在长上下文版本中，总序列长度可达256K

## 四、视频处理流程

### 1. 帧采样与分块
- 假设视频时长T秒，帧率f fps
- 采用**长度自适应采样**：根据训练阶段的序列长度限制动态调整采样帧数、fps和最大帧数
- 例如，对于长视频（>2分钟），可能采样1 fps，总帧数$N_f$ = T

### 2. 每帧独立编码
- 每帧通过上述图像处理流程提取视觉token
- 设每帧得到M个视觉token，则$N_f$帧共得到$N_f × M$个视觉token

### 3. 时间建模
#### a) 时间位置编码：Interleaved MRoPE
改进MRoPE，将时间、水平、垂直三个维度的旋转频率**交错分配**：
- 对于第t帧、位置(i,j)的token，其旋转角度为三维联合编码：
  $θ_combined = θₜ ⊕ θᵢ ⊕ θⱼ$
  其中⊕表示维度交错的频率组合

#### b) 显式时间戳标记
- 为每一段视频帧插入文本时间戳token，如`<3.0 seconds>`
- 时间戳作为普通文本token输入，使模型直接感知时间信息

### 4. 视频特征融合
- 所有帧的视觉token与时间戳token交错拼接，形成**交错多模态序列**
- 输入LLM的总序列长度 = 文本token数 + $N_f$ × M + 时间戳token数

### 5. 长视频适应（256K上下文）
- 在**Ultra-Long-Context Adaptation**阶段，模型训练时序列长度扩展至262,144
- 视频帧数和每帧token数可灵活调整，确保总token数 ≤ 256K

## 五、关键数学计算与维度总结

| 步骤 | 输入形状 | 操作 | 输出形状 | 关键数学计算 |
|------|----------|------|----------|--------------|
| 图像分块 | (3, 1248, 9376) | 14×14分块 | (59,630, 14, 14, 3) | Nh = H/14, Nw = W/14 |
| 线性投影 | (59,630, 588) | Z = X Wp | (59,630, D) | Wp ∈ ℝ^(588×D) |
| 2D-RoPE | (59,630, D) | 旋转位置编码 | (59,630, D) | θᵢ, θⱼ旋转矩阵 |
| ViT层处理 | (59,630, D) | MSA + FFN | (59,630, D) | Attention(Q,K,V) |
| DeepStack抽取 | 多层(59,630, D) | 取第l1,l2,l3层 | 3×(59,630, D) | 选择指定层输出 |
| MLP Merger | (59,630, D) | 两层MLP | (59,630, D') | σ(XW₁+b₁)W₂+b₂ |
| 2×2压缩 | (89×670, D') | 相邻2×2合并 | (44×335, D') | 平均或线性投影 |
| 视频帧堆叠 | $N_f×(M, D')$ | 拼接所有帧 | $(N_f×M, D')$ | 沿序列维度concat |
| 时间戳插入 | $(N_f×M, D')$ | 插入文本token | $(N_f×M + N_ts, D')$ | 文本嵌入查找 |
| 输入LLM | 总序列长度L | 与文本拼接 | (L, D') | 256K上下文支持 |

