# 25.12.16æ±‡æŠ¥ Qwen3-Next æ¨¡å‹æ¶æ„

## 1. æ•´ä½“æ¶æ„
- **æ€»å±‚æ•°**: 48å±‚ = 12 Ã— (3å±‚Gated DeltaNet + 1å±‚Gated Attention)çš„é‡å¤ç»“æ„
- **éšè—ç»´åº¦**: 2048

## 2. Gated DeltaNet ç»“æ„

### 2.1 ç»“æ„ä¿¡æ¯
| ç»„ä»¶ | å¤´æ•° | å¤´ç»´åº¦ | æ€»ç»´åº¦ |
|------|------|--------|--------|
| Q/K | 16 | 128 | 2048 (16Ã—128) |
| V   | 32 | 128 | 4096 (32Ã—128) |

### 2.2 çº¿æ€§æŠ•å½±
**è¾“å…¥**: `X` (å½¢çŠ¶: `[B, L, 2048]`)

**æŠ•å½±çŸ©é˜µ**: 
- `W_qkvz` (å½¢çŠ¶: `[2048, 12288]`)
- `12288 = k_dim(2048) + v_dim(4096) + z_dim(4096) + q_dim(2048)`
- `W_ba` (å½¢çŠ¶: `[2048, 64]`)

**æŠ•å½±æ“ä½œ**: 
```python
X @ W_qkvz = [q, k, v, z]  # æ€»ç»´åº¦ 12288
X @ W_ba = [b, a]  # æ€»ç»´åº¦ 64
```

**ç»´åº¦åˆ†è§£**:
- `q`: `[B, L, 32, 128]` (query)
- `k`: `[B, L, 16, 128]` (key)
- `v`: `[B, L, 16, 128]` (value)
- `z`: `[B, L, 32, 128]` (é—¨æ§å‚æ•°ï¼Œä¸qkvæŠ•å½±ä¸€èµ·å¾—åˆ°)
- `b`: `[B, L, 32]` (Î²å‚æ•°çš„åŸå§‹å€¼)
- `a`: `[B, L, 32]` (è¡°å‡å‡½æ•°çš„åŸå§‹å€¼)

### 2.3 å·ç§¯å˜æ¢
å¯¹ç‰¹å¾é€šé“è¿›è¡Œå·ç§¯å˜æ¢ï¼š
- `q`: `[B, L, 32, 128]` â†’ `[B, L, 4096]`
- `k`: `[B, L, 16, 128]` â†’ `[B, L, 2048]`
- `v`: `[B, L, 16, 128]` â†’ `[B, L, 2048]`

### 2.4 æ¿€æ´»å‡½æ•°
ä½¿ç”¨ **SiLUæ¿€æ´»å‡½æ•°**

### 2.5 Gated Delta Rule çº¿æ€§æ³¨æ„åŠ›

#### æ­¥éª¤1: é‡å¤qå’Œkå¤´ä»¥åŒ¹é…vå¤´æ•°
```python
Q_repeat = repeat(q, [1, 1, 2, 1])  # [B, L, 32, 128]
K_repeat = repeat(k, [1, 1, 2, 1])  # [B, L, 32, 128]
```

#### æ­¥éª¤2: DeltaNetçŠ¶æ€æ›´æ–°ï¼ˆé€’å½’å½¢å¼ï¼‰
```python
# åˆå§‹åŒ–çŠ¶æ€
S = zeros(B, 32, 128, 128)  # [B, 32, 128, 128]

# è®¡ç®—Î²å’Œg
Î² = torch.sigmoid(b) # (B, L, 32)
g = -self.A_log.float().exp() * F.softplus(a.float() + self.dt_bias) # (B, L, 32)

for t = 1 to L:
    # è·å–å½“å‰æ—¶é—´æ­¥çš„å„ä¸ªç»„ä»¶
    Q_t = Q_repeat[:, t, :, :]  # [B, 32, 128]
    K_t = K_repeat[:, t, :, :]  # [B, 32, 128]
    V_t = V[:, t, :, :]         # [B, 32, 128]
    Î²_t = Î²[:, t, :]            # [B, 32]
    g_t = exp(g[:, t, :])       # [B, 32]
    
    # æ‰©å±•ç»´åº¦ç”¨äºå¹¿æ’­
    g_t_exp = expand(g_t, [-1, -1, 128, 128])  # [B, 32, 128, 128]
    Î²_t_exp = expand(Î²_t, [-1, -1, 128])       # [B, 32, 128]
    
    # çŠ¶æ€æ›´æ–°
    S = S * g_t_exp                     # è¡°å‡
    Î”S = K_t^T @ (V_t * Î²_t_exp)        # å¤–ç§¯æ›´æ–°
    S = S + Î”S
    
    # è®¡ç®—è¾“å‡º
    O_t = Q_t @ S  # [B, 32, 128]
```

#### æ­¥éª¤3: åˆå¹¶æ‰€æœ‰æ—¶é—´æ­¥
```python
O = stack([O_t for t in 1..L], dim=1)  # [B, L, 32, 128]
```

### å¯¹æ¯”æ ‡å‡†æ³¨æ„åŠ›æ–¹æ³•
- `æ ‡å‡†æ³¨æ„åŠ›`  ï¼šO(B * L^2 * d), KVç¼“å­˜
- `Gated DeltaNetçº¿æ€§æ³¨æ„åŠ›` ï¼šO(B * L * d^2), å­˜å‚¨çŠ¶æ€S

## 3. Gated Attention ç»“æ„
> è¿›è¡Œè¡¥å……

## 4. MoE
### MoEæ•´ä½“æ¶æ„æ¦‚è§ˆ

Qwen3Nextçš„MoEæ¨¡å—é‡‡ç”¨**ç¨€ç–æ¿€æ´»çš„æ··åˆä¸“å®¶ç³»ç»Ÿ**ï¼Œä¸»è¦ç‰¹ç‚¹ï¼š
- **ä¸“å®¶æ•°é‡**ï¼š512ä¸ªä¸“å®¶
- **æ¿€æ´»ä¸“å®¶æ•°**ï¼šæ¯ä¸ªtokenæ¿€æ´»10ä¸ªä¸“å®¶ï¼ˆTop-10ï¼‰
- **å…±äº«ä¸“å®¶**ï¼š1ä¸ªå…±äº«ä¸“å®¶ï¼Œæ€»æ˜¯æ¿€æ´»
- **ä¸“å®¶ä¸­é—´ç»´åº¦**ï¼š512ï¼ˆMoEä¸“å®¶ï¼‰ï¼Œå…±äº«ä¸“å®¶æœ‰è‡ªå·±çš„ä¸­é—´ç»´åº¦
  
**å…³é”®é…ç½®**ï¼š
- `num_experts`: 512
- `num_experts_per_tok`: 10ï¼ˆæ¯ä¸ªtokenæ¿€æ´»çš„ä¸“å®¶æ•°ï¼‰
- `moe_intermediate_size`: 512ï¼ˆä¸“å®¶ä¸­é—´ç»´åº¦ï¼‰
- `shared_expert_intermediate_size`: å…±äº«ä¸“å®¶çš„ä¸­é—´ç»´åº¦ï¼ˆé€šå¸¸æ›´å¤§ï¼‰

### ğŸ”„ MoEæ¨¡å—çš„çŸ©é˜µè¿ç®—æµç¨‹

#### 1. **è¾“å…¥å‡†å¤‡**
```
è¾“å…¥: hidden_states âˆˆ â„^(BÃ—LÃ—H)  # B=batch, L=seq_len, H=hidden_size=2048

# é‡å¡‘ä¸º2DçŸ©é˜µ
hidden_states_reshaped = hidden_states.view(-1, H)  # (B*L, 2048)
```

#### 2. **é—¨æ§ç½‘ç»œï¼ˆRouterï¼‰è®¡ç®—**

##### **é—¨æ§æƒé‡çŸ©é˜µ**
```python
# weight: (512, 2048)
# hidden_states: (B*L, 2048)
router_logits = F.linear(hidden_states, weight)  # (B*L, 512)
```

#### **çŸ©é˜µè¿ç®—åˆ†è§£**
```
W_router âˆˆ â„^(512Ã—2048)  # è·¯ç”±å™¨æƒé‡
X âˆˆ â„^(B*LÃ—2048)         # å±•å¹³çš„è¾“å…¥

# çº¿æ€§å˜æ¢ï¼Œå¾—åˆ°çš„ç»“æœå¯çœ‹ä½œæ¯ä¸ªtokenå’Œ512ä¸ªä¸“å®¶ä¹‹é—´çš„å…³ç³»
router_logits = X @ W_router^T  # (B*LÃ—2048) @ (2048Ã—512) â†’ (B*LÃ—512)

# Softmaxè®¡ç®—ï¼ˆåˆ†ä¸“å®¶ç»´åº¦ï¼‰
router_probs = softmax(router_logits, dim=-1)  # (B*LÃ—512)

# Top-Ké€‰æ‹©
router_top_value, router_indices = topk(router_probs, k=10, dim=-1)
# router_top_value: (B*LÃ—10), router_indices: (B*LÃ—10)

### 3. **å…±äº«ä¸“å®¶è®¡ç®—**

#### **å…±äº«ä¸“å®¶MLPç»“æ„**
```python
class Qwen3NextMLP:
    def __init__(self):
        self.gate_proj = nn.Linear(2048, shared_intermediate_size)
        self.up_proj = nn.Linear(2048, shared_intermediate_size)
        self.down_proj = nn.Linear(shared_intermediate_size, 2048)
    
    def forward(self, x):
        return self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
```

#### **çŸ©é˜µè¿ç®—**
```
è¾“å…¥: X âˆˆ â„^(B*LÃ—2048)

# GateæŠ•å½±
W_gate_shared âˆˆ â„^(shared_intermediate_sizeÃ—2048)
gate_shared = X @ W_gate_shared^T  # (B*LÃ—shared_intermediate_size)

# UpæŠ•å½±
W_up_shared âˆˆ â„^(shared_intermediate_sizeÃ—2048)
up_shared = X @ W_up_shared^T  # (B*LÃ—shared_intermediate_size)

# æ¿€æ´»å’Œé€å…ƒç´ ä¹˜
hidden_shared = SiLU(gate_shared) * up_shared  # (B*LÃ—shared_intermediate_size)

# DownæŠ•å½±
W_down_shared âˆˆ â„^(2048Ã—shared_intermediate_size)
shared_expert_output = hidden_shared @ W_down_shared^T  # (B*LÃ—2048)

# å…±äº«ä¸“å®¶é—¨æ§
W_shared_gate âˆˆ â„^(1Ã—2048)
shared_gate = sigmoid(X @ W_shared_gate^T)  # (B*LÃ—1)
shared_expert_output = shared_expert_output * shared_gate  # å¹¿æ’­ä¹˜æ³•
```

### 4. **ç¨€ç–ä¸“å®¶è®¡ç®—ï¼ˆæ ¸å¿ƒï¼‰**

#### **ä¸“å®¶å‚æ•°å­˜å‚¨æ–¹å¼**
```python
class Qwen3NextExperts(nn.Module):
    def __init__(self, config):
        # 3Då‚æ•°å­˜å‚¨
        self.gate_up_proj = nn.Parameter(torch.empty(
            self.num_experts, 2 * self.intermediate_dim, self.hidden_dim
        ))  # (512, 1024, 2048)
        
        self.down_proj = nn.Parameter(torch.empty(
            self.num_experts, self.hidden_dim, self.intermediate_dim
        ))  # (512, 2048, 512)
```

#### **ç¨€ç–è®¡ç®—æµç¨‹**

**æ­¥éª¤1ï¼šåˆ›å»ºä¸“å®¶æ©ç **
```python
# router_indices: (B*L, 10) - æ¯ä¸ªtokené€‰ä¸­çš„10ä¸ªä¸“å®¶ç´¢å¼•
expert_mask = torch.nn.functional.one_hot(router_indices, num_classes=512)
# expert_mask: (B*L, 10, 512)

# è½¬ç½®ä»¥ä¾¿æŒ‰ä¸“å®¶å¤„ç†
expert_mask = expert_mask.permute(2, 1, 0)  # (512, 10, B*L)

# æ‰¾å‡ºå“ªäº›ä¸“å®¶è‡³å°‘è¢«ä¸€ä¸ªtokené€‰ä¸­
expert_hit = torch.greater(expert_mask.sum(dim=(-1, -2)), 0).nonzero()
# expert_hit: (æ´»è·ƒä¸“å®¶æ•°, 1)
```

**æ­¥éª¤2ï¼šç¨€ç–å¾ªç¯è®¡ç®—**
```python
final_hidden_states = torch.zeros_like(hidden_states_reshaped)  # (B*L, 2048)

for expert_idx in expert_hit:
    expert_idx = expert_idx[0]  # å½“å‰ä¸“å®¶ç´¢å¼•
    
    # æ‰¾åˆ°é€‰ä¸­è¯¥ä¸“å®¶çš„æ‰€æœ‰token
    top_k_pos, token_idx = torch.where(expert_mask[expert_idx])
    # top_k_pos: åœ¨è¯¥tokençš„top-kä¸­çš„ä½ç½® (0-9)
    # token_idx: tokenç´¢å¼•
    
    current_state = hidden_states_reshaped[token_idx]  # (num_tokens, 2048)
    
    # Gate-UpæŠ•å½±
    gate_up = current_state @ self.gate_up_proj[expert_idx].T  # (num_tokens, 1024)
    gate, up = gate_up.chunk(2, dim=-1)  # å„(num_tokens, 512)
    
    # æ¿€æ´»å’Œé€å…ƒç´ ä¹˜
    current_hidden_states = self.act_fn(gate) * up  # (num_tokens, 512)
    
    # DownæŠ•å½±
    current_hidden_states = current_hidden_states @ self.down_proj[expert_idx].T  # (num_tokens, 2048)
    
    # åº”ç”¨è·¯ç”±æƒé‡
    current_weights = router_top_value[token_idx, top_k_pos, None]  # (num_tokens, 1)
    current_hidden_states = current_hidden_states * current_weights
    
    # ç´¯åŠ åˆ°æœ€ç»ˆè¾“å‡º
    final_hidden_states.index_add_(0, token_idx, current_hidden_states)
```

#### **çŸ©é˜µè¿ç®—çš„ç­‰ä»·å½¢å¼**

è™½ç„¶å®é™…å®ç°æ˜¯ç¨€ç–å¾ªç¯ï¼Œä½†ä»æ•°å­¦ä¸Šå¯ä»¥è¡¨ç¤ºä¸ºï¼š

```
# å®šä¹‰ç¨€ç–å¼ é‡è¿ç®—
å¯¹äºæ¯ä¸ªä¸“å®¶eï¼š
    mask_e = expert_mask[e]  # (10, B*L)
    å¯¹äºmask_eä¸­çš„æ¯ä¸ªéé›¶ä½ç½®(k, t)ï¼š
        æƒé‡ = router_top_value[t, k]
        è¾“å…¥_t = hidden_states_reshaped[t]  # (2048)
        
        # ä¸“å®¶eçš„è®¡ç®—
        è¾“å‡º_e_t = SiLU(è¾“å…¥_t @ W_gate_up_e[:512]^T) * (è¾“å…¥_t @ W_gate_up_e[512:]^T)
        è¾“å‡º_e_t = è¾“å‡º_e_t @ W_down_e^T  # (2048)
        
        # åŠ æƒç´¯åŠ 
        final_hidden_states[t] += æƒé‡ * è¾“å‡º_e_t
```

### 5. **æœ€ç»ˆè¾“å‡ºåˆå¹¶**

```python
# æ·»åŠ å…±äº«ä¸“å®¶è¾“å‡º
final_hidden_states += shared_expert_output  # (B*L, 2048)

# é‡å¡‘å›3D
final_hidden_states = final_hidden_states.view(B, L, 2048)  # (B, L, 2048)
```

## ğŸ“ˆ ç»´åº¦å˜åŒ–æ€»è¡¨

| æ­¥éª¤ | æ“ä½œ | è¾“å…¥ç»´åº¦ | è¾“å‡ºç»´åº¦ | è¯´æ˜ |
|------|------|----------|----------|------|
| 1 | è¾“å…¥é‡å¡‘ | (B,L,2048) | (B*L,2048) | å±•å¹³ä»¥ä¾¿å¤„ç† |
| 2 | è·¯ç”±å™¨è®¡ç®— | (B*L,2048) | (B*L,512) | çº¿æ€§æŠ•å½±+softmax |
| 3 | Top-Ké€‰æ‹© | (B*L,512) | (B*L,10)Ã—2 | è·¯ç”±æƒé‡å’Œä¸“å®¶ç´¢å¼• |
| 4 | å…±äº«ä¸“å®¶è®¡ç®— | (B*L,2048) | (B*L,2048) | å®Œæ•´MLPè®¡ç®— |
| 5 | ä¸“å®¶æ©ç åˆ›å»º | (B*L,10) | (512,10,B*L) | one-hotç¼–ç +è½¬ç½® |
| 6 | ç¨€ç–ä¸“å®¶è®¡ç®— | å¤šä¸ªè¾“å…¥ | (B*L,2048) | å¾ªç¯è®¡ç®—æ´»è·ƒä¸“å®¶ |
| 7 | åˆå¹¶è¾“å‡º | (B*L,2048)Ã—2 | (B*L,2048) | åŠ å’Œ |
| 8 | è¾“å‡ºé‡å¡‘ | (B*L,2048) | (B,L,2048) | æ¢å¤åºåˆ—ç»´åº¦ |

### MoEçš„æ ¸å¿ƒè®¾è®¡

#### 1. **ç¨€ç–æ¿€æ´»æœºåˆ¶**
- æ¯ä¸ªtokenåªæ¿€æ´»10/512ä¸ªä¸“å®¶ï¼ˆ~2%ï¼‰
- å¤§å¹…é™ä½è®¡ç®—é‡ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹å®¹é‡

#### 2. **3Då‚æ•°å­˜å‚¨**
```
gate_up_proj: (512, 1024, 2048)  # æ‰€æœ‰ä¸“å®¶çš„gate+upå‚æ•°
down_proj: (512, 2048, 512)      # æ‰€æœ‰ä¸“å®¶çš„downå‚æ•°
```
- ä¾¿äºæ‰¹é‡ç´¢å¼•å’Œè®¡ç®—
- å†…å­˜è¿ç»­ï¼Œè®¿é—®é«˜æ•ˆ

#### 3. **è´Ÿè½½å‡è¡¡æŸå¤±**

åœ¨è®­ç»ƒæ—¶æ·»åŠ è¾…åŠ©æŸå¤±å‡½æ•°ï¼Œç¡®ä¿ä¸“å®¶ä½¿ç”¨å‡è¡¡ï¼š

```python
def load_balancing_loss_func(gate_logits, num_experts, top_k, attention_mask):
    # gate_logits: å„å±‚çš„è·¯ç”±å™¨logitså…ƒç»„
    # è®¡ç®—æ¯ä¸ªä¸“å®¶è¢«é€‰ä¸­çš„æ¦‚ç‡
    # è®¡ç®—æ¯ä¸ªä¸“å®¶çš„tokenåˆ†é…æ¯”ä¾‹
    # æŸå¤± = num_experts * Î£(æ¦‚ç‡ * åˆ†é…æ¯”ä¾‹)
```

**æ•°å­¦å…¬å¼**ï¼š
```
å¯¹äºæ¯ä¸ªMoEå±‚ï¼š
    P = softmax(router_logits)  # (B*L, E)
    A = topk_mask(P)  # (B*L, E)ï¼Œé€‰ä¸­ä¸º1å¦åˆ™ä¸º0
    
    # ä¸“å®¶ä½¿ç”¨é¢‘ç‡
    expert_usage = mean(A, dim=0)  # (E,)
    # è·¯ç”±å™¨æ¦‚ç‡
    router_prob = mean(P, dim=0)   # (E,)
    
    # è´Ÿè½½å‡è¡¡æŸå¤±
    loss_lb = num_experts * sum(expert_usage * router_prob)
```

#### 4. **å…±äº«ä¸“å®¶è®¾è®¡**
- æ€»æ˜¯æ¿€æ´»ï¼Œæä¾›åŸºç¡€å¤„ç†èƒ½åŠ›
- é—¨æ§æœºåˆ¶æ§åˆ¶å…±äº«ä¸“å®¶çš„è´¡çŒ®ç¨‹åº¦
- ç¡®ä¿å³ä½¿ç¨€ç–è·¯ç”±æœ‰é—®é¢˜ï¼Œä¹Ÿæœ‰ç¨³å®šè¾“å‡º

### è®¡ç®—å¤æ‚åº¦åˆ†æ

### å¯†é›†è®¡ç®—ï¼ˆç†è®ºä¸Šï¼‰ï¼š
```
æ¯ä¸ªtokençš„ä¸“å®¶è®¡ç®—ï¼š
512ä¸ªä¸“å®¶ Ã— (2048Ã—512 + 512Ã—2048) = 512 Ã— 2.1M â‰ˆ 1.07B æ“ä½œ/token
```

#### ç¨€ç–è®¡ç®—ï¼ˆå®é™…ï¼‰ï¼š
```
æ¯ä¸ªtokençš„ä¸“å®¶è®¡ç®—ï¼š
10ä¸ªä¸“å®¶ Ã— (2048Ã—512 + 512Ã—2048) = 10 Ã— 2.1M â‰ˆ 21M æ“ä½œ/token
```

**è®¡ç®—å‡å°‘**ï¼šçº¦51å€ï¼ˆ512/10ï¼‰

#### å†…å­˜è®¿é—®æ¨¡å¼ï¼š
```
# å¯†é›†è®¡ç®—ï¼šéœ€è¦åŠ è½½æ‰€æœ‰512ä¸ªä¸“å®¶çš„å‚æ•°
å†…å­˜è®¿é—®é‡: 512 Ã— (1024+512)Ã—2048 Ã— 4å­—èŠ‚ â‰ˆ 6.3GB

# ç¨€ç–è®¡ç®—ï¼šåªåŠ è½½10ä¸ªæ´»è·ƒä¸“å®¶çš„å‚æ•°
å†…å­˜è®¿é—®é‡: 10 Ã— (1024+512)Ã—2048 Ã— 4å­—èŠ‚ â‰ˆ 123MB
```

